{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffbf325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 8\n",
      "1.0 0.17766498 0 0.21319798 43 0.12182741 20\n",
      "0.5 0.12182741 11 0.29441625 40 0.12182741 14\n",
      "0.1 0.12182741 12 0.5076142 24 0.12182741 17\n",
      "0.05 0.1928934 3 0.57360405 31 0.12182741 29\n",
      "0.01 0.4568528 36 0.52284265 42 0.48730963 45\n",
      "0.05 0.21319798 3 0.55837566 46 0.12182741 17\n",
      "0.001 0.57360405 45 0.25888324 47 0.56345177 48\n",
      "0.0005 0.56345177 37 0.21827412 47 0.52284265 42\n",
      "0.0001 0.2741117 37 0.065989845 19 0.29441625 45\n",
      "5e-05 0.21319798 45 0.12690355 21 0.2538071 46\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('8/8_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('8/8_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('8/8_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 8')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "ahyper=torch.load('8/8_best_model_hyperparams.pt')\n",
    "shyper=torch.load('8/8_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('8/8_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d17037ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 16\n",
      "1.0 0.12182741 14 0.28426397 46 0.12182741 7\n",
      "0.5 0.12182741 12 0.4720812 41 0.12182741 46\n",
      "0.1 0.14720812 2 0.5888325 49 0.12182741 33\n",
      "0.05 0.36548224 38 0.56852794 44 0.31979695 46\n",
      "0.01 0.52791876 49 0.42639595 46 0.52284265 41\n",
      "0.05 0.31979695 22 0.66497463 44 0.3248731 44\n",
      "0.001 3.253221e+33 47 0.21319798 32 0.61421317 47\n",
      "0.0005 0.56345177 45 0.2284264 48 0.52791876 32\n",
      "0.0001 0.27918783 48 0.08629441 33 0.3857868 41\n",
      "5e-05 0.17766498 8 0.11675127 33 0.2538071 47\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('16/16_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('16/16_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('16/16_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 16')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "ahyper=torch.load('16/16_best_model_hyperparams.pt')\n",
    "shyper=torch.load('16/16_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('16/16_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ad79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 24\n",
      "1.0 0.21827412 1 0.39593908 47 0.12182741 9\n",
      "0.5 0.12182741 11 0.5177665 44 0.12182741 20\n",
      "0.1 0.19796954 8 0.52791876 29 0.12182741 19\n",
      "0.05 0.35532996 44 0.5888325 41 0.21319798 4\n",
      "0.01 0.52791876 28 0.40609136 49 0.47715735 46\n",
      "0.05 0.37563452 39 0.56852794 39 0.39086294 44\n",
      "0.001 0.5786802 45 0.22335026 42 0.61928934 45\n",
      "0.0005 0.52791876 46 0.26395938 49 0.55837566 33\n",
      "0.0001 0.29441625 47 0.18274112 43 0.2994924 49\n",
      "5e-05 0.2284264 47 0.10152284 33 0.30964467 41\n",
      "{'learning_rate': 0.001, 'epoch': 46, 'batch_size': 24}\n",
      "{'learning_rate': 0.05, 'epoch': 41, 'batch_size': 24}\n",
      "{'learning_rate': 0.001, 'epoch': 45, 'batch_size': 24}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('24/24_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('24/24_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('24/24_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 24')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "    \n",
    "ahyper=torch.load('24/24_best_model_hyperparams.pt')\n",
    "shyper=torch.load('24/24_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('24/24_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "935f4ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 32\n",
      "1.0 0.12182741 9 0.5177665 48 0.12182741 19\n",
      "0.5 0.12182741 15 0.5431472 40 0.12182741 18\n",
      "0.1 0.2538071 40 0.56345177 31 0.20812182 32\n",
      "0.05 0.46192893 39 0.5177665 49 0.3604061 37\n",
      "0.01 0.56345177 20 0.3857868 47 0.57360405 43\n",
      "0.05 0.4720812 49 0.5431472 49 0.3604061 46\n",
      "0.001 0.5786802 43 0.20812182 44 0.61421317 45\n",
      "0.0005 0.43654823 45 0.2741117 47 0.5482234 41\n",
      "0.0001 0.24365482 46 0.14213198 43 0.23350254 38\n",
      "5e-05 0.18274112 49 0.12690355 33 0.19796954 47\n",
      "{'learning_rate': 0.01, 'epoch': 49, 'batch_size': 32}\n",
      "{'learning_rate': 0.1, 'epoch': 31, 'batch_size': 32}\n",
      "{'learning_rate': 0.001, 'epoch': 45, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('32/32_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('32/32_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('32/32_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 32')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "ahyper=torch.load('32/32_best_model_hyperparams.pt')\n",
    "shyper=torch.load('32/32_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('32/32_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f0bf43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 48\n",
      "1.0 0.13197969 1 0.46192893 45 0.12182741 15\n",
      "0.5 0.12690355 1 0.46192893 46 0.12182741 43\n",
      "0.1 0.26395938 39 0.61928934 25 0.12182741 1\n",
      "0.05 0.33502537 45 0.5786802 49 0.23857868 44\n",
      "0.01 0.5532995 25 0.30456853 42 0.4568528 36\n",
      "0.05 0.5786802 35 0.46700507 44 0.23350254 32\n",
      "0.001 0.5329949 39 0.20304568 24 0.56852794 31\n",
      "0.0005 0.49238577 45 0.16751269 49 0.49746192 43\n",
      "0.0001 0.19796954 41 0.11675127 1 0.37563452 48\n",
      "5e-05 0.14720812 49 0.08629441 0 0.26903552 13\n",
      "{'learning_rate': 0.01, 'epoch': 33, 'batch_size': 48}\n",
      "{'learning_rate': 0.05, 'epoch': 49, 'batch_size': 48}\n",
      "{'learning_rate': 0.001, 'epoch': 38, 'batch_size': 48}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('48/48_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('48/48_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('48/48_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 48')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "ahyper=torch.load('48/48_best_model_hyperparams.pt')\n",
    "shyper=torch.load('48/48_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('48/48_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "941b009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE = 64\n",
      "1.0 0.12182741 7 0.5431472 42 0.12182741 26\n",
      "0.5 0.12690355 3 0.42639595 46 0.12182741 38\n",
      "0.1 0.2893401 46 0.52284265 33 0.23857868 26\n",
      "0.05 0.5837563 37 0.4720812 37 0.3401015 38\n",
      "0.01 0.40609136 46 0.24873096 41 0.56345177 39\n",
      "0.05 0.45177665 42 0.55837566 46 0.17258883 46\n",
      "0.001 0.57360405 33 0.12690355 42 0.5786802 46\n",
      "0.0005 0.3401015 48 0.1573604 48 0.48730963 49\n",
      "0.0001 0.20812182 49 0.11167513 8 0.24365482 45\n",
      "5e-05 0.1573604 25 0.11167513 33 0.17766498 49\n",
      "{'learning_rate': 0.001, 'epoch': 48, 'batch_size': 64}\n",
      "{'learning_rate': 0.1, 'epoch': 45, 'batch_size': 64}\n",
      "{'learning_rate': 0.001, 'epoch': 46, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "adam_accuracies = torch.load('64/64_Accuracies_results.pt')\n",
    "sgd_accuracies = torch.load('64/64_Accuracies_results_sgd.pt')\n",
    "rms_accuracies = torch.load('64/64_Accuracies_results_rmsprop.pt')\n",
    "LearningRate=[1.0,0.5,0.1,0.05,0.01,0.05,0.001,0.0005,0.0001,0.00005]\n",
    "print('BATCH SIZE = 64')\n",
    "for i in range(10):\n",
    "    avalues, aindices= torch.topk(adam_accuracies[i],1)\n",
    "    svalues, sindices= torch.topk(sgd_accuracies[i],1)\n",
    "    pvalues, pindices= torch.topk(rms_accuracies[i],1)    \n",
    "    print(LearningRate[i],avalues.numpy()[0],aindices.numpy()[0],svalues.numpy()[0],sindices.numpy()[0],pvalues.numpy()[0],pindices.numpy()[0])\n",
    "ahyper=torch.load('64/64_best_model_hyperparams.pt')\n",
    "shyper=torch.load('64/64_best_model_hyperparams_sgd.pt')\n",
    "phyper=torch.load('64/64_best_model_hyperparams_rmsprop.pt')\n",
    "print(ahyper)\n",
    "print(shyper)\n",
    "print(phyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8849f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2532e+33)\n",
      "tensor(0.6650)\n",
      "tensor(0.6142)\n"
     ]
    }
   ],
   "source": [
    "print(adam_accuracies.max())\n",
    "print(sgd_accuracies.max())\n",
    "print(rms_accuracies.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76408a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Load data\n",
    "data_path = '16/16_Accuracies_results_sgd.pt'\n",
    "Accuracies_lr = torch.load(data_path)  \n",
    "LearningRate = [1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005]\n",
    "\n",
    "# Viridis colormap\n",
    "cmap = plt.get_cmap('viridis') \n",
    "\n",
    "# Plot colors\n",
    "colors = cmap(np.linspace(0, 1, Accuracies_lr.shape[0]))\n",
    "colors = colors.tolist()\n",
    "\n",
    "# Plot  \n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "for i in range(Accuracies_lr.shape[0]):\n",
    "    ax.plot(range(Accuracies_lr.shape[1]), Accuracies_lr[i], color=colors[i])\n",
    "    \n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.grid()\n",
    "\n",
    "# Legend\n",
    "for i in range(Accuracies_lr.shape[0]):\n",
    "    ax.annotate(str(LearningRate[i]), xy=(1.0, Accuracies_lr[i, -1]),\n",
    "                xycoords='data', xytext=(350, 0), textcoords='offset points', \n",
    "                color=colors[i])\n",
    "      \n",
    "# Learning rate colorbar\n",
    "cmap_ax = fig.add_axes([1.02, 0.1, 0.02, 0.8])\n",
    "# Get min and max learning rates\n",
    "lr_min = min(LearningRate) \n",
    "lr_max = max(LearningRate)\n",
    "norm = mpl.colors.LogNorm(vmin=lr_min, vmax=lr_max) \n",
    "cb = mpl.colorbar.ColorbarBase(cmap_ax, cmap=cmap,norm=norm, orientation='vertical')\n",
    "cb.set_label('Learning Rate')\n",
    "\n",
    "# Update colorbar ticks\n",
    "\n",
    "# Set dynamic ticks\n",
    "cb.set_ticks(LearningRate)\n",
    "\n",
    "# Format tick labels \n",
    "cb.set_ticklabels([\"{:.5f}\".format(lr) for lr in LearningRate])\n",
    "\n",
    "# Layout  \n",
    "fig.subplots_adjust(right=0.85)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880af635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
